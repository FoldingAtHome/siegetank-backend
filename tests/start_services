#! /usr/bin/env python3

# Start services necessary to test the core.
import os
import subprocess
import time
import requests
import json
import base64
import gzip
import pymongo
import sys

import utils


def add_engine_token(manager_token):
    headers = {'Authorization': manager_token}
    reply = requests.post('https://127.0.0.1:8980/engines/keys',
                          data=json.dumps({"engine": "openmm",
                                           "description": "hehehe"}),
                          headers=headers,
                          verify=False)
    assert reply.status_code == 200
    return reply.json()['key']


def post_target(auth_token, stage='private'):
    message = json.dumps({'engines': ['openmm'],
                          'options': {
                              'title': 'DHFR',
                              'description': 'This is a simulation of the DHFR protein and serves as a good benchmark.',
                              'steps_per_frame': 10000
                          },
                          'stage': stage,
                          'weight': 1,
                          })
    reply = requests.post('https://127.0.0.1:8980/targets',
                          headers={'Authorization': auth_token},
                          verify=False,
                          data=message,
                          )
    return json.loads(reply.content.decode())['target_id']


def post_streams(target_id, files, auth_token):
    message = json.dumps({'target_id': target_id,
                          'files': files})
    reply = requests.post('https://127.0.0.1:8960/streams',
                          headers={'Authorization': auth_token},
                          verify=False,
                          data=message
                          )
    print(reply.text)
    assert reply.status_code == 200
    return json.loads(reply.content.decode())['stream_id']

if __name__ == '__main__':
    # if a pids.log exists, that means we need to do some cleanup!
    mdb = pymongo.MongoClient()
    for db_name in mdb.database_names():
        mdb.drop_database(db_name)
    if os.path.exists('pids.log'):
        stop_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                 'stop_services')
        os.system(stop_path)
    cc_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                           '..', 'cc')
    log = open('pids.log', 'w')
    if '--noscv' not in sys.argv:
        scv_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                '..', 'scv')
        pid2 = subprocess.Popen(scv_path, stdout=subprocess.PIPE, shell=True,
                                preexec_fn=lambda: os.setpgid(0, 0))
        time.sleep(1)
        log.write(str(pid2.pid))
        log.write(' ')
    pid1 = subprocess.Popen(cc_path, stdout=subprocess.PIPE, shell=True,
                            preexec_fn=lambda: os.setpgid(0, 0))
    time.sleep(1)
    log.write(str(pid1.pid))
    log.close()
    result = utils.add_user(manager=True, admin=True)
    token = result['token']
    core_key = add_engine_token(token)
    # post a public target
    target_id = post_target(token, stage='public')
    state_url = 'http://web.stanford.edu/~yutongz/state.xml.gz'
    system_url = 'http://web.stanford.edu/~yutongz/system.xml.gz'
    integrator_url = 'http://web.stanford.edu/~yutongz/integrator.xml.gz'
    state_gz = requests.get(state_url).content
    system_gz = requests.get(system_url).content
    integrator_gz = requests.get(integrator_url).content
    encoded_system = base64.b64encode(system_gz).decode()
    encoded_intg = base64.b64encode(integrator_gz).decode()
    encoded_state = base64.b64encode(state_gz).decode()
    files = {
        'system.xml.gz.b64': encoded_system,
        'state.xml.gz.b64': encoded_state,
        'integrator.xml.gz.b64': encoded_intg
    }
    for i in range(20):
        post_streams(target_id, files, token)

    target_id = post_target(token)
    post_streams(target_id, files, token)

    # post a private target
    with open('target_ids.log', 'w') as log:
        log.write(str(target_id))
    with open('core_keys.log', 'w') as log:
        log.write(str(core_key))
    with open('donor_tokens.log', 'w') as log:
        log.write(str(token))
